# 2. 顶层设计

Ext4文件系统是由众多块组构成。为了减少由于碎片造成的性能困难，块分配器会非常努力地将每个文件的块保留在同一组中，从而减少寻道时间。块组的大小在 ```sb.s_blocks_per_group``` 中指定，也可以由 ```8 * block_size_in_bytes```算出来。块大小默认为**4KB**，每个块组包含了**32768** 个块，所以大小为**128MB**。块组的数量可以由存储设备的大小除以当个块组大小得出来。  
ext4 中的所有字段都按小端写入磁盘，但是，jbd2（日志）中的所有字段都按大端写入磁盘。

## 2.1. 块

ext4 以"块"为单位分配存储空间。块是介于 1KiB 和 64KiB 之间的一组扇区，扇区数必须是 2 的指数倍。比块更大的单位是由块组成的块组。块大小在 ```mkfs``` 时指定，通常为 4KiB。如果块大小大于页的大小（比如在 只有 4KiB页大小的i386上创建 64KiB 大小的块），则可能会遇到安装问题。默认情况下，文件系统可以包含 2^32 个块。如果启用了"64 位"功能，则文件系统可以有 2^64 个块。

## 2.2. 块组的布局

标准的块组布局大致如下分布:
![](/assets/block_group_layout.png)

块组0的情况比较特殊，前1024个字节是保留字节以允许安装x86启动扇区和其他用途。超级块将以偏移量 1024 字节开始，通常为块0。但是，如果由于某种原因块大小等于1024字节，则超级块为块1。对于其他块组则没有偏移。

ext4驱动程序主要使用块组0中的超级块和组描述符。超级块和组描述符的冗余副本将写入磁盘上的某些块组，以防磁盘开头被破坏，尽管并非所有块组都必须承载冗余副本（有关详细信息，请参阅以下段落）。如果组没有冗余副本，则块组以```data block bitmap```开始。此外，当文件系统新格式化时，mkfs 将在块组描述符之后和块位映射开始之前分配" ```reserve GDT block``` "空间，以允许文件系统将来扩展。默认情况下，允许文件系统的大小比原始文件系统大小增加 1024 倍。


inode 表的位置由```grp.bg_inode_table_*```表示。拥有足够大的连续的块，足以包含 ```sb.s_inodes_per_group * sb.s_inode_size```字节大小。

对于块组中各个项的排序，通常确定超级块和组描述符表（如果存在）将位于块组的开头。位图和 inode 表可以是任意位置，并且位图很有可能位于 inode 表之后，或者两者都位于不同的组中 （flex_bg）。剩余空间用于文件数据块、间接块映射、范围树块和扩展属性。

## 2.3. 可变块组

从 ext4 开始，有一个称为灵活块组 （flex_bg） 的新功能。在 flex_bg 中，多个块组作为一个逻辑块组绑定在一起; flex_bg 的第一个块组中的位图空间和 inode 表空间被展开，以包括 flex_bg 中所有其他块组的位图和 inode 表。例如，如果 flex_bg 大小为 4，则组 0 将包含（按顺序）超级块、组描述符、组 0-3 的数据块位图、组 0-3 的 inode 位图、组 0-3 的 inode 表，组 0 中的剩余空间用于文件数据。这样做的效果是将块元数据紧密地组合在一起以加快加载速度，并使大型文件能够在磁盘上连续运行。超级块和组描述符的备份副本始终位于块组的开头，即使启用了 flex_bg 也是如此。构成 flex_bg 的块组数等于```2 ^ sb.s_log_groups_per_flex```。


## 2.4. 元块组

如果没有选项 META_BG（在 ext3 中），为了安全性方面的考虑，所有的块描述符信息全部被保存到第一个块组中，因此以缺省的 128MB （227 B）大小的块组为例，最多能够支持 227 / 32 = 222 个块组，最大支持的文件系统大小为 222 * 227 = 249 B= 512 TB。而ext4_group_desc 目前的大小为 44 字节，以后会扩充到 64 字节，所能够支持的文件系统最大只有 256 TB。

为了解决这个问题，ext4 中采用了元块组（metablock group）的概念。所谓元块组就是指块组的集群，其组描述符结构可以存储在单个磁盘块中或在一个数据块中的一些连续块组。仍然以 128MB 的块组（数据块为 4KB）为例，ext4 中每个元块组可以包括 4096 / 64 = 64 个块组，即每个元块组的大小是 64 * 128 MB = 8 GB。 元块组功能将组描述符的位置从整个文件系统的拥塞的第一个块组移动到每个元块组本身的第一组。备份位于每个元块组的第二组和最后一组。这将 2^21 的最大块组限制增加到硬限制 2^32，从而允许支持 512PiB 文件系统。

采用元块组的概念之后，每个元块组中的块组描述符都变成定长的，这对于文件系统的扩展非常有利。采用元块组概念之后，如果需要扩充文件系统的大小，可以在现有数据块之后新添加磁盘数据块，并将这些数据块也按照元块组的方式进行管理即可，这样就可以突破文件系统大小原有的限制了。当然，为了使用这些新增加的空间，在 superblock 结构中需要增加一些字段来记录相关信息。（ext4_super_block 结构中增加了一个 s_first_meta_bg 字段用来引用第一个元块组的位置，这样还可以解决原有块组和新的元块组共存的问题。）

ext3 与 ext4 磁盘布局对比:  

![](https://www.ibm.com/developerworks/cn/linux/l-cn-filesrc5/images/image001.jpg)

## 2.5. 块组的懒初始化

ext4 的新功能是三个块组描述符标志，使 mkfs 能够跳过初始化块组元数据的其他部分。具体而言，INODE_UNINIT 和 BLOCK_UNINIT 标志意味着仅计算该组的 inode 和块位图，不会初始化磁盘位图块。对于空块组或仅包含固定位置块组元数据的块组，通常情况就是这种情况。INODE_ZEROED 标志表示 inode 表已初始化;mkfs 将取消设置此标志，并依靠内核在后台初始化 inode 表。

通过不将零写入位图和 inode 表，mkfs 时间大大减少。请注意，功能标志是 RO_COMPAT_GDT_CSUM，但dumpe2fs 输出将此打印为"uninit_bg"。它们是一回事。

## 2.6. 特殊的索引节点

ext4 为特殊功能保留一些 inode，如下所示：

| inode Number | Purpose |
| ------ | ------ | 
| 0 | Doesn't exist; there is no inode 0. |
| 1 | List of defective blocks. |
| 2 | Root directory. |
| 3 | User quota. |
| 4 | Group quota. |
| 5 | Boot loader. |
| 6 | Undelete directory. |
| 7 | Reserved group descriptors inode. (“resize inode”) |
| 8 | Journal inode. |
| 9 | The “exclude” inode, for snapshots(?) |
| 10 | Replica inode, used for some non-upstream feature? |
| 11 | Traditional first non-reserved inode. Usually this is the lost+found directory. See s_first_ino in the superblock. |

## 2.7. 块和 Inode 分配策略

ext4认为比 ext3 要好，文件系统的好坏可以用本地化数据体现。在旋转磁盘上，将相关块彼此靠近可减少头执行器和磁盘访问数据块所必须执行的移动量，从而加快磁盘 IO。在 SSD 上，当然没有移动部件，但紧凑的数据可以增加每个传输请求的大小，同时减少请求的总数。还可能具有将写入集中到单个擦除块上的效果，这可显著加快文件重写速度。因此，尽可能减少碎片是很有用的。

ext4 用于消除碎片的第一个工具是多块分配器。首次创建文件时，块分配器会推测地将 8KiB 的磁盘空间分配给文件，前提是空间将很快写入。当文件关闭时，未使用的推测分配当然被释放，但如果推测是正确的（通常情况下，小文件的完整写入），然后文件数据在单个多块范围内写入。ext4 使用的第二个相关技巧是延迟分配。根据此方案，当文件需要更多的块来吸收文件写入时，文件系统会推迟决定磁盘上的确切位置，直到所有脏缓冲区都写入磁盘。通过绝对必要（调用提交超时或 ```sync（）```或内核耗尽内存）之前不提交到特定位置，希望文件系统能够做出更好的位置决策。

ext4（和 ext3）使用的第三个技巧是，它尝试将文件的数据块保留在与其 inode 相同的块组中。当文件系统首先必须读取文件的 inode 以了解文件的数据块位于何处，然后查找到文件的数据块以开始 I/O 操作时，这减少了搜索带来的损耗。

第四个技巧是，在可行的情况下，目录中的所有 inode 都放置在与目录相同的块组中。此处的工作假设是目录中的所有文件可能都是相关的，因此尝试将它们放在一起非常有用。

第五个技巧是磁盘卷被切成 128MB 的块组;如上文所述，这些微型容器用于尝试维护数据本地化。但是，有一个故意的怪癖 - 当在根目录中创建目录时，inode 分配器将扫描块组，并将该目录放入它可以找到的负载最少的块组中。这鼓励目录分散在磁盘上;当顶级目录/二进制文件填满一个块组时，分配器只需移动到下一个块组。据称，这一方案将块组的加载均匀化，最坏的性能表现是那些非常倒霉的目录在旋转驱动器的末端。

当然，如果所有这些机制都失败了，人们总是可以使用```e4defrag```对文件进行碎片整理。

## 2.8. 校验值

从 2012 年初开始，元数据校验和添加到所有主要 ext4 和 jbd2 数据结构中。关联的功能标志是```metadata_csum```。在超级块中指示了所需的校验和算法，但截至 2012 年 10 月，唯一受支持的算法是 **crc32c**。某些数据结构没有空间来容纳完整的 32 位校验指，因此仅存储较低的 16 位。启用 64 位功能可增加数据结构大小，以便可以为许多数据结构存储完整的 32 位校验指。但是，现有的 32 位文件系统无法扩展以启用 64 位模式，至少实验性的```resize2fs```补丁可以来修复这一点。


现有文件系统可以通过对基础设备运行```tune2fs -O metadata_csum``来添加校验。如果 tune2fs 遇到没有足够的空白空间来添加校验和的目录块，它将请求您运行 e2fsck -D，以便使用校验和重新生成目录。这还有一个额外的好处，从目录文件中删除松弛空间并重新平衡 htree 索引。如果您 [忽略] 此步骤，您的目录将不受校验和的保护！



















































